# System Requirements - Social Work Survey Application

## 1. System Overview and User Roles

This web-based application is designed for social work research, integrating survey management, user administration, multimedia communication, and data analysis. The system supports three user types: Administrators, Social Workers, and Participants. Administrators have full system access, managing users and configuring the system. Social Workers create surveys, manage participants, and analyze data. Participants respond to surveys and communicate with assigned Social Workers.

## 2. User Management and Authentication

The user management module handles account creation, modification, and deletion. Administrators can assign participants to social workers in one-to-one or one-to-many configurations. The system implements role-based access control (RBAC) with customizable permissions. Social workers manage their assigned participants, update profiles, and monitor activity. Participants can update their profiles and view assigned surveys.

Authentication uses a multi-factor approach. The login system includes username/password authentication and two-factor authentication (2FA). Password policies enforce complexity requirements, regular changes, and a recovery process. The RBAC system restricts user access based on assigned roles.

## 3. Messaging System and Communication

The messaging system facilitates communication between users based on predefined rules. Participants message only their assigned social worker. Social workers communicate with assigned participants, other social workers, and administrators. The system includes group chat functionality for social workers.

Supported content types include text with formatting, images, videos, audio files, documents, and other file types, subject to size and type restrictions. Features include real-time messaging, file sharing with progress tracking, full-text search, date filters, read receipts, typing indicators, emoji support, message editing and deletion, and thread-based conversations. The notification system uses in-app, email, and push notifications.

## 4. Survey Management and Distribution

The survey builder uses a page-by-page construction interface with drag-and-drop functionality. Question types include multiple choice, single choice, yes/no, short and long text, numerical inputs, date and time selectors, file uploads, rating scales, ranking systems, matrices, Likert scales, Net Promoter Score (NPS), semantic differential scales, image choices, sliders, and geolocation inputs. Questions can be configured as optional or required, with validation rules, randomization options, and dynamic content using piping and placeholder text.

Survey navigation options include linear progression, conditional branching with skip and display logic, and custom routing based on responses. The system includes a progress bar. Customization options allow for branding with colors, fonts, logo placement, and custom CSS support.

The survey library includes categorization, tagging, version control, and collaborative editing features. Survey testing capabilities include desktop and mobile previews, a test mode with simulated responses, and an accessibility checker.

Survey distribution methods include email invitations, unique links, and QR codes. The system supports setting availability periods and quota management.

## 5. Response Collection, Analysis, and LLM Integration

Data collection features real-time response gathering, progress saving for partial completions, and offline mode with synchronization. The system includes response validation and duplicate prevention mechanisms. Data visualization tools offer customizable charts, graphs, and mapping options. Analysis features include cross-tabulation, filtering, and trend analysis.

Export capabilities support CSV, Excel, PDF, and SPSS formats, with customizable templates and scheduled exports. Access control restricts data visibility based on user roles.

The LLM-based Data Analysis Engine allows natural language querying of data, automated insight generation, sentiment analysis, topic modeling, and predictive analytics. It integrates with survey responses and chat logs. The engine includes customizable analysis parameters and features for explaining how insights are generated.

# Technical Architecture and Design Specification: Social Work Survey Application

## 1. High-Level Architecture

- **Frontend**: 
  - Framework: React.js (version 18.x)
  - State Management: Redux with Redux Toolkit
  - Routing: React Router (version 6.x)
  - UI Component Library: Material-UI (version 5.x)
  - Form Handling: Formik with Yup validation
  - HTTP Client: Axios

- **Backend**: 
  - Runtime: Node.js (version 18.x LTS)
  - Framework: Express.js (version 4.x)
  - API Documentation: Swagger/OpenAPI 3.0
  - Process Manager: PM2

- **Databases**: 
  - Relational: PostgreSQL (version 14.x)
  - ORM: Drizzle ORM
  - Document Store: MongoDB (version 6.x)
  - ODM: Mongoose for MongoDB

- **Authentication & Authorization**: 
  - JSON Web Tokens (JWT) with refresh token rotation
  - Role-Based Access Control (RBAC)
  - Passport.js for strategy management

- **Real-time Communication**: 
  - WebSocket protocol using Socket.io (version 4.x)
  - Redis Pub/Sub for scaling WebSocket across multiple servers

- **File Storage**: 
  - Azure Blob Storage
  - Azure SDK for JavaScript

- **Caching**: 
  - Redis (version 6.x)
  - Implementation: ioredis client, cache-manager for flexible caching strategies

- **Search**: 
  - Elasticsearch (version 8.x)
  - Client: @elastic/elasticsearch official Node.js client

- **Machine Learning**: 
  - Integration with OpenAI GPT-4 or Anthropic's Claude API
  - Python runtime for code execution and data analysis

- **Deployment**: 
  - Containerization: Docker (version 20.x)
  - Orchestration: Kubernetes (version 1.26.x)
  - CI/CD: GitLab CI/CD or GitHub Actions

## 2. Authorization and Authentication

### 2.1 Authentication

1. JWT-based authentication
   - Short-lived access tokens (15 minutes)
   - Longer-lived refresh tokens (7 days)
   - Refresh token rotation for enhanced security

2. Login flow:
   - User submits credentials
   - Server validates credentials
   - If valid, server issues access token and refresh token
   - Tokens stored in HttpOnly, secure cookies

3. Token refresh flow:
   - Client sends refresh token
   - Server validates refresh token
   - If valid, server issues new access token and refresh token
   - Old refresh token is invalidated

### 2.2 Authorization (Role-Based Access Control)

1. User Roles:
   - Administrator
   - Social Worker
   - Participant

2. Permission structure:
```javascript
const permissions = {
  CREATE_SURVEY: ['Administrator', 'Social Worker'],
  EDIT_SURVEY: ['Administrator', 'Social Worker'],
  DELETE_SURVEY: ['Administrator'],
  VIEW_ALL_SURVEYS: ['Administrator'],
  VIEW_OWN_SURVEYS: ['Social Worker', 'Participant'],
  MANAGE_USERS: ['Administrator'],
  ASSIGN_PARTICIPANTS: ['Administrator', 'Social Worker'],
  VIEW_ANALYTICS: ['Administrator', 'Social Worker'],
  SEND_MESSAGES: ['Administrator', 'Social Worker', 'Participant'],
}
```

3. Middleware for checking permissions:
```javascript
const checkPermission = (requiredPermission) => {
  return (req, res, next) => {
    const userRole = req.user.role;
    if (permissions[requiredPermission].includes(userRole)) {
      next();
    } else {
      res.status(403).json({ error: 'Forbidden' });
    }
  };
};
```

4. Usage in routes:
```javascript
router.post('/surveys', checkPermission('CREATE_SURVEY'), createSurvey);
```

## 3. Database Schema (PostgreSQL with Drizzle ORM)

```typescript
import { pgTable, uuid, varchar, timestamp, boolean } from 'drizzle-orm/pg-core';

export const users = pgTable('users', {
  id: uuid('id').defaultRandom().primaryKey(),
  username: varchar('username', { length: 255 }).notNull().unique(),
  email: varchar('email', { length: 255 }).notNull().unique(),
  passwordHash: varchar('password_hash', { length: 255 }).notNull(),
  role: varchar('role', { length: 20 }).notNull(),
  createdAt: timestamp('created_at').defaultNow().notNull(),
  updatedAt: timestamp('updated_at').defaultNow().notNull(),
});

export const surveys = pgTable('surveys', {
  id: uuid('id').defaultRandom().primaryKey(),
  title: varchar('title', { length: 255 }).notNull(),
  description: varchar('description', { length: 1000 }),
  creatorId: uuid('creator_id').references(() => users.id),
  isActive: boolean('is_active').default(true).notNull(),
  createdAt: timestamp('created_at').defaultNow().notNull(),
  updatedAt: timestamp('updated_at').defaultNow().notNull(),
});

export const responses = pgTable('responses', {
  id: uuid('id').defaultRandom().primaryKey(),
  surveyId: uuid('survey_id').references(() => surveys.id),
  participantId: uuid('participant_id').references(() => users.id),
  completedAt: timestamp('completed_at'),
  createdAt: timestamp('created_at').defaultNow().notNull(),
  updatedAt: timestamp('updated_at').defaultNow().notNull(),
});

export const userAssignments = pgTable('user_assignments', {
  id: uuid('id').defaultRandom().primaryKey(),
  socialWorkerId: uuid('social_worker_id').references(() => users.id),
  participantId: uuid('participant_id').references(() => users.id),
  assignedAt: timestamp('assigned_at').defaultNow().notNull(),
});
```

## 4. File Storage (Azure Blob Storage)

1. Configuration:
```javascript
const { BlobServiceClient } = require('@azure/storage-blob');

const blobServiceClient = BlobServiceClient.fromConnectionString(process.env.AZURE_STORAGE_CONNECTION_STRING);
const containerClient = blobServiceClient.getContainerClient('survey-attachments');
```

2. File upload function:
```javascript
async function uploadFile(file, filename) {
  const blockBlobClient = containerClient.getBlockBlobClient(filename);
  const uploadBlobResponse = await blockBlobClient.upload(file.buffer, file.buffer.length);
  return blockBlobClient.url;
}
```

3. File download function:
```javascript
async function downloadFile(filename) {
  const blockBlobClient = containerClient.getBlockBlobClient(filename);
  const downloadBlockBlobResponse = await blockBlobClient.download(0);
  return downloadBlockBlobResponse.readableStreamBody;
}
```

## 5. LLM Integration (ChatGPT/Claude-like interface with Python execution)

1. LLM Service Client:
```javascript
const axios = require('axios');
const { PythonShell } = require('python-shell');

class LLMClient {
  constructor(apiKey, baseURL) {
    this.apiKey = apiKey;
    this.baseURL = baseURL;
    this.axios = axios.create({
      baseURL,
      headers: { 'Authorization': `Bearer ${apiKey}` }
    });
  }

  async query(prompt, context = {}) {
    try {
      const response = await this.axios.post('/v1/chat/completions', {
        model: 'gpt-4',
        messages: [
          { role: 'system', content: 'You are an AI assistant capable of analyzing survey data and generating insights. You can also execute Python code to perform statistical analysis and create visualizations.' },
          { role: 'user', content: prompt }
        ],
        context
      });
      return response.data.choices[0].message.content;
    } catch (error) {
      console.error('LLM query failed:', error);
      throw error;
    }
  }

  async executePython(code) {
    return new Promise((resolve, reject) => {
      PythonShell.runString(code, null, (err, results) => {
        if (err) reject(err);
        else resolve(results);
      });
    });
  }
}

const llmClient = new LLMClient(process.env.OPENAI_API_KEY, 'https://api.openai.com');
```

2. Example usage in API endpoint:
```javascript
router.post('/analysis/llm-query', async (req, res) => {
  const { query, context } = req.body;
  try {
    const llmResponse = await llmClient.query(query, context);
    
    // Check if the response contains Python code
    const pythonCodeMatch = llmResponse.match(/```python([\s\S]*?)```/);
    if (pythonCodeMatch) {
      const pythonCode = pythonCodeMatch[1].trim();
      const pythonResult = await llmClient.executePython(pythonCode);
      
      res.json({
        llmResponse,
        pythonResult
      });
    } else {
      res.json({ llmResponse });
    }
  } catch (error) {
    res.status(500).json({ error: 'Analysis failed' });
  }
});
```

# Complete Specification: Social Work Survey Application

## 1. System Overview

The Social Work Survey Application is a web-based platform designed to facilitate survey creation, distribution, and analysis for social work research. The system supports three user roles: Administrators, Social Workers, and Participants. It provides features for survey management, user administration, secure messaging, and data analysis powered by Large Language Models (LLMs).

### 1.1 Key Features

- User authentication and role-based access control
- Survey creation, editing, and distribution
- Secure messaging between social workers and participants
- File upload and storage for survey attachments
- LLM-powered data analysis with Python code execution capabilities
- Real-time notifications for new messages and survey responses

## 2. Technology Stack

### 2.1 Frontend
- Framework: React.js (version 18.x)
- State Management: Redux with Redux Toolkit
- Routing: React Router (version 6.x)
- UI Component Library: Material-UI (version 5.x)
- Form Handling: Formik with Yup validation
- HTTP Client: Axios

### 2.2 Backend
- Runtime: Node.js (version 18.x LTS)
- Framework: Express.js (version 4.x)
- API Documentation: Swagger/OpenAPI 3.0
- Process Manager: PM2

### 2.3 Databases
- Relational: PostgreSQL (version 14.x) with Drizzle ORM
- Document Store: MongoDB (version 6.x) with Mongoose ODM

### 2.4 Authentication & Authorization
- JSON Web Tokens (JWT) with refresh token rotation
- Passport.js for strategy management

### 2.5 Real-time Communication
- WebSocket protocol using Socket.io (version 4.x)
- Redis Pub/Sub for scaling WebSocket across multiple servers

### 2.6 File Storage
- Azure Blob Storage
- Azure SDK for JavaScript

### 2.7 Caching
- Redis (version 6.x)
- Implementation: ioredis client, cache-manager for flexible caching strategies

### 2.8 Search
- Elasticsearch (version 8.x)
- Client: @elastic/elasticsearch official Node.js client

### 2.9 Machine Learning
- Integration with OpenAI GPT-4 or Anthropic's Claude API
- Python runtime for code execution and data analysis

### 2.10 Deployment
- Containerization: Docker (version 20.x)
- Orchestration: Kubernetes (version 1.26.x)
- CI/CD: GitLab CI/CD or GitHub Actions

## 3. System Architecture

### 3.1 Frontend Architecture

The frontend will be a Single Page Application (SPA) built with React.js. It will use the following architecture:

1. Components
   - Presentational components (UI elements)
   - Container components (data fetching and state management)
2. Pages
   - Represent different routes in the application
3. Services
   - API calls to the backend
   - WebSocket management
4. State Management
   - Redux store with slices for different features
   - Thunks for asynchronous actions
5. Routing
   - React Router for navigation
   - Protected routes for authenticated users

### 3.2 Backend Architecture

The backend will follow a layered architecture:

1. Routes Layer
   - Defines API endpoints
   - Handles request/response
2. Controller Layer
   - Implements business logic
   - Coordinates between services
3. Service Layer
   - Encapsulates complex operations
   - Interacts with repositories and external services
4. Repository Layer
   - Handles data access and persistence
   - Implements database queries using Drizzle ORM and Mongoose
5. Middleware
   - Authentication
   - Error handling
   - Logging
6. WebSocket Layer
   - Manages real-time communications

## 4. Database Design

### 4.1 PostgreSQL Schema (using Drizzle ORM)

```typescript
import { pgTable, uuid, varchar, timestamp, boolean, jsonb } from 'drizzle-orm/pg-core';

export const users = pgTable('users', {
  id: uuid('id').defaultRandom().primaryKey(),
  username: varchar('username', { length: 255 }).notNull().unique(),
  email: varchar('email', { length: 255 }).notNull().unique(),
  passwordHash: varchar('password_hash', { length: 255 }).notNull(),
  role: varchar('role', { length: 20 }).notNull(),
  createdAt: timestamp('created_at').defaultNow().notNull(),
  updatedAt: timestamp('updated_at').defaultNow().notNull(),
});

export const surveys = pgTable('surveys', {
  id: uuid('id').defaultRandom().primaryKey(),
  title: varchar('title', { length: 255 }).notNull(),
  description: varchar('description', { length: 1000 }),
  creatorId: uuid('creator_id').references(() => users.id),
  isActive: boolean('is_active').default(true).notNull(),
  createdAt: timestamp('created_at').defaultNow().notNull(),
  updatedAt: timestamp('updated_at').defaultNow().notNull(),
});

export const responses = pgTable('responses', {
  id: uuid('id').defaultRandom().primaryKey(),
  surveyId: uuid('survey_id').references(() => surveys.id),
  participantId: uuid('participant_id').references(() => users.id),
  answers: jsonb('answers').notNull(),
  completedAt: timestamp('completed_at'),
  createdAt: timestamp('created_at').defaultNow().notNull(),
  updatedAt: timestamp('updated_at').defaultNow().notNull(),
});

export const userAssignments = pgTable('user_assignments', {
  id: uuid('id').defaultRandom().primaryKey(),
  socialWorkerId: uuid('social_worker_id').references(() => users.id),
  participantId: uuid('participant_id').references(() => users.id),
  assignedAt: timestamp('assigned_at').defaultNow().notNull(),
});

export const messages = pgTable('messages', {
  id: uuid('id').defaultRandom().primaryKey(),
  senderId: uuid('sender_id').references(() => users.id),
  receiverId: uuid('receiver_id').references(() => users.id),
  content: varchar('content', { length: 5000 }).notNull(),
  isRead: boolean('is_read').default(false).notNull(),
  createdAt: timestamp('created_at').defaultNow().notNull(),
  updatedAt: timestamp('updated_at').defaultNow().notNull(),
});

export const attachments = pgTable('attachments', {
  id: uuid('id').defaultRandom().primaryKey(),
  messageId: uuid('message_id').references(() => messages.id),
  fileName: varchar('file_name', { length: 255 }).notNull(),
  fileUrl: varchar('file_url', { length: 1000 }).notNull(),
  fileType: varchar('file_type', { length: 50 }).notNull(),
  createdAt: timestamp('created_at').defaultNow().notNull(),
});
```

### 4.2 MongoDB Schema (using Mongoose)

```javascript
const mongoose = require('mongoose');

const SurveySchema = new mongoose.Schema({
  surveyId: { type: String, required: true, unique: true },
  structure: {
    questions: [{
      id: String,
      type: String,
      text: String,
      options: [String],
      required: Boolean,
      validation: Object
    }],
    logic: [{
      if: { question: String, answer: String },
      then: { action: String, target: String }
    }]
  }
});

const SurveyModel = mongoose.model('Survey', SurveySchema);
```

## 5. API Endpoints

### 5.1 Authentication

- POST /api/auth/login
- POST /api/auth/register
- POST /api/auth/refresh-token
- POST /api/auth/logout

### 5.2 User Management

- GET /api/users
- GET /api/users/:id
- PUT /api/users/:id
- DELETE /api/users/:id
- POST /api/users/:id/assign-participant

### 5.3 Survey Management

- GET /api/surveys
- POST /api/surveys
- GET /api/surveys/:id
- PUT /api/surveys/:id
- DELETE /api/surveys/:id
- POST /api/surveys/:id/distribute

### 5.4 Response Collection

- POST /api/surveys/:id/responses
- GET /api/surveys/:id/responses
- GET /api/surveys/:id/responses/:responseId

### 5.5 Messaging

- GET /api/messages
- POST /api/messages
- GET /api/messages/:id
- PUT /api/messages/:id
- DELETE /api/messages/:id
- POST /api/messages/:id/attachment

### 5.6 Data Analysis

- POST /api/analysis/llm-query

## 6. Authentication and Authorization

### 6.1 JWT-based Authentication

1. Login Flow:
   - User submits credentials
   - Server validates credentials
   - If valid, server issues access token (15 min expiry) and refresh token (7 days expiry)
   - Tokens stored in HttpOnly, secure cookies

2. Token Refresh Flow:
   - Client sends refresh token
   - Server validates refresh token
   - If valid, server issues new access token and refresh token
   - Old refresh token is invalidated

### 6.2 Role-Based Access Control (RBAC)

User Roles:
- Administrator
- Social Worker
- Participant

Permission structure:
```javascript
const permissions = {
  CREATE_SURVEY: ['Administrator', 'Social Worker'],
  EDIT_SURVEY: ['Administrator', 'Social Worker'],
  DELETE_SURVEY: ['Administrator'],
  VIEW_ALL_SURVEYS: ['Administrator'],
  VIEW_OWN_SURVEYS: ['Social Worker', 'Participant'],
  MANAGE_USERS: ['Administrator'],
  ASSIGN_PARTICIPANTS: ['Administrator', 'Social Worker'],
  VIEW_ANALYTICS: ['Administrator', 'Social Worker'],
  SEND_MESSAGES: ['Administrator', 'Social Worker', 'Participant'],
}
```

Middleware for checking permissions:
```javascript
const checkPermission = (requiredPermission) => {
  return (req, res, next) => {
    const userRole = req.user.role;
    if (permissions[requiredPermission].includes(userRole)) {
      next();
    } else {
      res.status(403).json({ error: 'Forbidden' });
    }
  };
};
```

## 7. File Storage (Azure Blob Storage)

### 7.1 Configuration

```javascript
const { BlobServiceClient } = require('@azure/storage-blob');

const blobServiceClient = BlobServiceClient.fromConnectionString(process.env.AZURE_STORAGE_CONNECTION_STRING);
const containerClient = blobServiceClient.getContainerClient('survey-attachments');
```

### 7.2 File Operations

1. Upload:
```javascript
async function uploadFile(file, filename) {
  const blockBlobClient = containerClient.getBlockBlobClient(filename);
  const uploadBlobResponse = await blockBlobClient.upload(file.buffer, file.buffer.length);
  return blockBlobClient.url;
}
```

2. Download:
```javascript
async function downloadFile(filename) {
  const blockBlobClient = containerClient.getBlockBlobClient(filename);
  const downloadBlockBlobResponse = await blockBlobClient.download(0);
  return downloadBlockBlobResponse.readableStreamBody;
}
```

3. Delete:
```javascript
async function deleteFile(filename) {
  const blockBlobClient = containerClient.getBlockBlobClient(filename);
  await blockBlobClient.delete();
}
```

## 8. LLM Integration

### 8.1 LLM Service Client

```javascript
const axios = require('axios');
const { PythonShell } = require('python-shell');

class LLMClient {
  constructor(apiKey, baseURL) {
    this.apiKey = apiKey;
    this.baseURL = baseURL;
    this.axios = axios.create({
      baseURL,
      headers: { 'Authorization': `Bearer ${apiKey}` }
    });
  }

  async query(prompt, context = {}) {
    try {
      const response = await this.axios.post('/v1/chat/completions', {
        model: 'gpt-4',
        messages: [
          { role: 'system', content: 'You are an AI assistant capable of analyzing survey data and generating insights. You can also execute Python code to perform statistical analysis and create visualizations.' },
          { role: 'user', content: prompt }
        ],
        context
      });
      return response.data.choices[0].message.content;
    } catch (error) {
      console.error('LLM query failed:', error);
      throw error;
    }
  }

  async executePython(code) {
    return new Promise((resolve, reject) => {
      PythonShell.runString(code, null, (err, results) => {
        if (err) reject(err);
        else resolve(results);
      });
    });
  }
}

const llmClient = new LLMClient(process.env.OPENAI_API_KEY, 'https://api.openai.com');
```

### 8.2 LLM Query Endpoint

```javascript
router.post('/analysis/llm-query', async (req, res) => {
  const { query, context } = req.body;
  try {
    const llmResponse = await llmClient.query(query, context);
    
    // Check if the response contains Python code
    const pythonCodeMatch = llmResponse.match(/```python([\s\S]*?)```/);
    if (pythonCodeMatch) {
      const pythonCode = pythonCodeMatch[1].trim();
      const pythonResult = await llmClient.executePython(pythonCode);
      
      res.json({
        llmResponse,
        pythonResult
      });
    } else {
      res.json({ llmResponse });
    }
  } catch (error) {
    res.status(500).json({ error: 'Analysis failed' });
  }
});
```

## 9. Real-time Communications

### 9.1 WebSocket Setup

```javascript
const socketIo = require('socket.io');
const redis = require('redis');
const redisAdapter = require('socket.io-redis');

const io = socketIo(server);
const pubClient = redis.createClient(process.env.REDIS_URL);
const subClient = pubClient.duplicate();

io.adapter(redisAdapter({ pubClient, subClient }));

io.use((socket, next) => {
  const token = socket.handshake.auth.token;
  // Verify JWT token
  // If valid, attach user info to socket
  // If invalid, call next(new Error('Authentication error'));
});

io.on('connection', (socket) => {
  console.log('New client connected');
  
  socket.on('join:room', (roomId) => {
    socket.join(roomId);
  });

  socket.on('message:send', (message) => {
    // Save message to database
    // Emit message to room
    io.to(message.roomId).emit('message:received', message);
  });

  socket.on('disconnect', () => {
    console.log('Client disconnected');
  });
});
```

## 10. Deployment

### 10.1 Docker Configuration

Dockerfile:
```dockerfile
FROM node:18

WORKDIR /usr/src/app

COPY package*.json ./

RUN npm install

COPY . .

EXPOSE 8080

CMD [ "node", "server.js" ]
```

### 10.2 Kubernetes Deployment

deployment.yaml:
```yaml
apiVersion: apps/v1
kind:
[Continuation of the previous content...]

### 10.2 Kubernetes Deployment

deployment.yaml:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: social-work-survey-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: social-work-survey-app
  template:
    metadata:
      labels:
        app: social-work-survey-app
    spec:
      containers:
      - name: social-work-survey-app
        image: your-registry/social-work-survey-app:latest
        ports:
        - containerPort: 8080
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: database-url
        - name: AZURE_STORAGE_CONNECTION_STRING
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: azure-storage-connection-string
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: openai-api-key
```

service.yaml:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: social-work-survey-app-service
spec:
  selector:
    app: social-work-survey-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
  type: LoadBalancer
```

### 10.3 CI/CD Pipeline (GitLab CI)

.gitlab-ci.yml:
```yaml
stages:
  - test
  - build
  - deploy

test:
  stage: test
  image: node:18
  script:
    - npm install
    - npm run test

build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker build -t your-registry/social-work-survey-app:$CI_COMMIT_SHA .
    - docker push your-registry/social-work-survey-app:$CI_COMMIT_SHA

deploy:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl set image deployment/social-work-survey-app social-work-survey-app=your-registry/social-work-survey-app:$CI_COMMIT_SHA
```

## 11. Security Considerations

### 11.1 Data Encryption

- Use HTTPS for all communications
- Encrypt sensitive data at rest in the database
- Use Azure's built-in encryption for blob storage

### 11.2 Input Validation and Sanitization

- Implement strict input validation on both client and server side
- Use parameterized queries to prevent SQL injection
- Sanitize user inputs to prevent XSS attacks

### 11.3 Rate Limiting

Implement rate limiting to prevent abuse:

```javascript
const rateLimit = require("express-rate-limit");

const apiLimiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100 // limit each IP to 100 requests per windowMs
});

app.use("/api/", apiLimiter);
```

### 11.4 Security Headers

Use Helmet middleware to set security headers:

```javascript
const helmet = require("helmet");
app.use(helmet());
```

### 11.5 Regular Security Audits

- Conduct regular security audits and penetration testing
- Keep all dependencies up to date
- Monitor for and address any reported vulnerabilities in used libraries

## 12. Testing Strategy

### 12.1 Unit Testing

Use Jest for unit testing:

```javascript
const sum = require('./sum');

test('adds 1 + 2 to equal 3', () => {
  expect(sum(1, 2)).toBe(3);
});
```

### 12.2 Integration Testing

Use Supertest for API integration tests:

```javascript
const request = require('supertest');
const app = require('../app');

describe('Post Endpoints', () => {
  it('should create a new post', async () => {
    const res = await request(app)
      .post('/api/posts')
      .send({
        title: 'test is cool',
        content: 'Lorem ipsum'
      });
    expect(res.statusCode).toEqual(201);
    expect(res.body).toHaveProperty('post');
  });
});
```

### 12.3 End-to-End Testing

Use Cypress for end-to-end testing:

```javascript
describe('Login', () => {
  it('should login with valid credentials', () => {
    cy.visit('/login');
    cy.get('#email').type('user@example.com');
    cy.get('#password').type('password123');
    cy.get('button[type="submit"]').click();
    cy.url().should('include', '/dashboard');
  });
});
```

### 12.4 Performance Testing

Use Apache JMeter to conduct performance tests, simulating high load scenarios.

## 13. Monitoring and Logging

### 13.1 Application Monitoring

Use Prometheus and Grafana for monitoring:

```javascript
const promClient = require('prom-client');
const collectDefaultMetrics = promClient.collectDefaultMetrics;
collectDefaultMetrics({ timeout: 5000 });

const httpRequestDurationMicroseconds = new promClient.Histogram({
  name: 'http_request_duration_ms',
  help: 'Duration of HTTP requests in ms',
  labelNames: ['method', 'route', 'code'],
  buckets: [0.1, 5, 15, 50, 100, 500]
});

app.use((req, res, next) => {
  const start = Date.now();
  res.on('finish', () => {
    const duration = Date.now() - start;
    httpRequestDurationMicroseconds
      .labels(req.method, req.route.path, res.statusCode)
      .observe(duration);
  });
  next();
});
```

### 13.2 Logging

Use Winston for logging:

```javascript
const winston = require('winston');

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.json(),
  defaultMeta: { service: 'social-work-survey-app' },
  transports: [
    new winston.transports.File({ filename: 'error.log', level: 'error' }),
    new winston.transports.File({ filename: 'combined.log' })
  ]
});

if (process.env.NODE_ENV !== 'production') {
  logger.add(new winston.transports.Console({
    format: winston.format.simple()
  }));
}

module.exports = logger;
```

## 14. Maintenance and Support

### 14.1 Regular Updates

- Schedule regular updates for all dependencies
- Plan for major version upgrades of key libraries and frameworks

### 14.2 Database Maintenance

- Regular backups of PostgreSQL and MongoDB databases
- Implement a retention policy for backups
- Schedule regular database optimizations and clean-ups

### 14.3 Monitoring and Alerting

- Set up alerts for abnormal application behavior
- Monitor system resources and scale as needed
- Implement an on-call rotation for addressing critical issues

### 14.4 Documentation

- Maintain up-to-date documentation for all APIs
- Document all deployment and maintenance procedures
- Keep a changelog for all updates and changes to the system

## 15. Scalability Plan

### 15.1 Database Scaling

- Implement database sharding for PostgreSQL as data grows
- Set up MongoDB replica sets for improved read performance

### 15.2 Application Scaling

- Use Kubernetes Horizontal Pod Autoscaler to automatically scale based on CPU utilization or custom metrics
- Implement caching strategies to reduce database load

### 15.3 Storage Scaling

- Utilize Azure Blob Storage's automatic scaling capabilities
- Monitor storage usage and adjust retention policies as needed

This completes the comprehensive specification for the Social Work Survey Application. It covers all aspects of the system from architecture and design to deployment, security, testing, and maintenance. This document should serve as a guide for development, deployment, and ongoing management of the application.